{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (0.27.2)\r\n",
      "Requirement already satisfied: pinecone-client in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: datasets in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (2.10.1)\r\n",
      "Requirement already satisfied: requests>=2.20 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from openai) (2.28.2)\r\n",
      "Requirement already satisfied: tqdm in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from openai) (4.65.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from openai) (3.8.4)\r\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from pinecone-client) (2.3.0)\r\n",
      "Requirement already satisfied: loguru>=0.5.0 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from pinecone-client) (0.6.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from pinecone-client) (2.8.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.4 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from pinecone-client) (6.0)\r\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from pinecone-client) (1.26.15)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from pinecone-client) (4.5.0)\r\n",
      "Requirement already satisfied: numpy in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from pinecone-client) (1.24.2)\r\n",
      "Requirement already satisfied: packaging in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from datasets) (23.0)\r\n",
      "Requirement already satisfied: xxhash in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from datasets) (3.2.0)\r\n",
      "Requirement already satisfied: multiprocess in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from datasets) (0.70.14)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from datasets) (0.13.3)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from datasets) (2023.3.0)\r\n",
      "Requirement already satisfied: responses<0.19 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from datasets) (0.18.0)\r\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from datasets) (0.3.6)\r\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from datasets) (11.0.0)\r\n",
      "Requirement already satisfied: pandas in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from datasets) (1.5.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from aiohttp->openai) (22.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from aiohttp->openai) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from aiohttp->openai) (1.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from aiohttp->openai) (1.8.2)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from aiohttp->openai) (4.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from aiohttp->openai) (3.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from aiohttp->openai) (6.0.4)\r\n",
      "Requirement already satisfied: filelock in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from requests>=2.20->openai) (2022.9.24)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from requests>=2.20->openai) (3.4)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/osuz/PycharmProjects/YaServiceRu/venv/lib/python3.9/site-packages (from pandas->datasets) (2022.7.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openai pinecone-client datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<OpenAIObject list at 0x12509d180> JSON: {\n  \"data\": [\n    {\n      \"created\": null,\n      \"id\": \"babbage\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"davinci\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"babbage-code-search-code\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-similarity-babbage-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-davinci-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"ada\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"curie-instruct-beta\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"babbage-code-search-text\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"babbage-similarity\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"gpt-3.5-turbo\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"code-search-babbage-text-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-curie-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"gpt-3.5-turbo-0301\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"code-cushman-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"code-search-babbage-code-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-davinci-insert-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-ada-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-embedding-ada-002\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-internal\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-similarity-ada-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-davinci-insert-002\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"code-davinci-002\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"ada-code-search-code\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"ada-similarity\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"whisper-1\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-internal\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-davinci-003\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-internal\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"code-search-ada-text-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-search-ada-query-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"davinci-search-document\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"ada-code-search-text\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-search-ada-doc-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"davinci-instruct-beta\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-similarity-curie-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"code-search-ada-code-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"ada-search-query\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-search-davinci-query-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"curie-search-query\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"davinci-search-query\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"babbage-search-document\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"ada-search-document\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-search-curie-query-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-search-babbage-doc-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"curie-search-document\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-search-curie-doc-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"babbage-search-query\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-babbage-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"code-davinci-edit-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-search-davinci-doc-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-search-babbage-query-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"curie-similarity\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"curie\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-davinci-edit-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-similarity-davinci-001\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"text-davinci-002\",\n      \"object\": \"engine\",\n      \"owner\": \"openai\",\n      \"permissions\": null,\n      \"ready\": true\n    },\n    {\n      \"created\": null,\n      \"id\": \"davinci-similarity\",\n      \"object\": \"engine\",\n      \"owner\": \"openai-dev\",\n      \"permissions\": null,\n      \"ready\": true\n    }\n  ],\n  \"object\": \"list\"\n}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from configparser import ConfigParser\n",
    "\n",
    "constants = ConfigParser()\n",
    "constants.read(\"/Users/osuz/PycharmProjects/YaServiceRu/resources/constants.ini\")\n",
    "\n",
    "# get API key from top-right dropdown on OpenAI website\n",
    "openai.api_key = constants.get(\"API\", \"OPENAI\")\n",
    "\n",
    "openai.Engine.list()  # check we have authenticated"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=MODEL\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# extract embeddings to a list\n",
    "embeds = [record['embedding'] for record in res['data']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=constants.get(\"API\", \"PINECONE\"),\n",
    "    environment=constants.get(\"API\", \"PINECONE_ENVIRONMENT\")  # may be different, check at app.pinecone.io\n",
    ")\n",
    "\n",
    "# check if 'openai' index already exists (only create index if not)\n",
    "if 'openai' not in pinecone.list_indexes():\n",
    "    pinecone.create_index('openai', dimension=len(embeds[0]))\n",
    "# connect to index\n",
    "index = pinecone.Index('openai')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/5.09k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e15ef0d35f843dab5797d2cee81f52f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading metadata:   0%|          | 0.00/3.34k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d8560c44c804e78933114d713dcf646"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading readme:   0%|          | 0.00/10.6k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d6c40ebe1c04b5ba985ef33cd3aaf0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset trec/default to /Users/osuz/.cache/huggingface/datasets/trec/default/2.0.0/f2469cab1b5fceec7249fda55360dfdbd92a7a5b545e91ea0f78ad108ffac1c2...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98222fc58d6d4053a111da859392bd60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/336k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddc4a64f21b14600b562afaaeeb7c2c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/23.4k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f8c760e97e347f392ffc49fece332d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/5452 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3004d31a8a374111b38d80d6ae0a37aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52abf96fd01e4a7b99d78631992a517d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset trec downloaded and prepared to /Users/osuz/.cache/huggingface/datasets/trec/default/2.0.0/f2469cab1b5fceec7249fda55360dfdbd92a7a5b545e91ea0f78ad108ffac1c2. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the first 1K rows of the TREC dataset\n",
    "trec = load_dataset('trec', split='train[:1000]')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e744de66ba64d29ad2a95c27651cf67"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm  # this is our progress bar\n",
    "\n",
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(trec['text']), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(trec['text']))\n",
    "    # get batch of lines and IDs\n",
    "    lines_batch = trec['text'][i: i+batch_size]\n",
    "    ids_batch = [str(n) for n in range(i, i_end)]\n",
    "    # create embeddings\n",
    "    res = openai.Embedding.create(input=lines_batch, engine=MODEL)\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    # prep metadata and upsert batch\n",
    "    meta = [{'text': line} for line in lines_batch]\n",
    "    to_upsert = zip(ids_batch, embeds, meta)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "query = \"What caused the 1929 Great Depression?\"\n",
    "\n",
    "xq = openai.Embedding.create(input=query, engine=MODEL)['data'][0]['embedding']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "res = index.query([xq], top_k=5, include_metadata=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92: Why did the world enter a global depression in 1929 ?\n",
      "0.87: When was `` the Great Depression '' ?\n",
      "0.81: What crop failure caused the Irish Famine ?\n",
      "0.80: What historical event happened in Dogtown in 1899 ?\n",
      "0.79: What caused the Lynmouth floods ?\n"
     ]
    }
   ],
   "source": [
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88: Why did the world enter a global depression in 1929 ?\n",
      "0.83: When was `` the Great Depression '' ?\n",
      "0.81: What crop failure caused the Irish Famine ?\n",
      "0.80: When did World War I start ?\n",
      "0.80: What were popular songs and types of songs in the 1920s ?\n"
     ]
    }
   ],
   "source": [
    "query = \"What was the cause of the major recession in the early 20th century?\"\n",
    "\n",
    "# create the query embedding\n",
    "xq = openai.Embedding.create(input=query, engine=MODEL)['data'][0]['embedding']\n",
    "\n",
    "# query, returning the top 5 most similar results\n",
    "res = index.query([xq], top_k=5, include_metadata=True)\n",
    "\n",
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90: Why did the world enter a global depression in 1929 ?\n",
      "0.84: When was `` the Great Depression '' ?\n",
      "0.80: When did World War I start ?\n",
      "0.80: What crop failure caused the Irish Famine ?\n",
      "0.80: When did the Dow first reach ?\n"
     ]
    }
   ],
   "source": [
    "query = \"Why was there a long-term economic downturn in the early 20th century?\"\n",
    "\n",
    "# create the query embedding\n",
    "xq = openai.Embedding.create(input=query, engine=MODEL)['data'][0]['embedding']\n",
    "\n",
    "# query, returning the top 5 most similar results\n",
    "res = index.query([xq], top_k=5, include_metadata=True)\n",
    "\n",
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
